{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9eca6f",
   "metadata": {},
   "source": [
    "A script to prepare questionnaire data for analysis.\n",
    "\n",
    "Outputs can be saved at multiple stages according to what you want to analyse, by uncommenting the save as csv lines.\n",
    "\n",
    "**Change the data directory at the start and the output directory at the end to match those on your PC**\n",
    "\n",
    "If you have any unicode errors when reading the csv, make sure there is 'r' before the string (pd.read_csv(r'...string goes here...'). \n",
    "\n",
    "If this doesn't resolve the issue, repeat the backslashes each time (e.g., C:\\\\Users\\\\...), or use forward slashes instead (even if using Windows - e.g., C:/Users/...)\n",
    "\n",
    "Make sure to have entered an additional column 'Study' in the import file\n",
    "\n",
    "By Danielle Hewitt, Jan 2023. Last updated, 12th March 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d43923b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>location</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>litpq_want_5_9</th>\n",
       "      <th>litpq_want_6_1</th>\n",
       "      <th>litpq_want_6_2</th>\n",
       "      <th>litpq_want_6_3</th>\n",
       "      <th>litpq_want_6_4</th>\n",
       "      <th>litpq_want_6_5</th>\n",
       "      <th>litpq_want_6_6</th>\n",
       "      <th>litpq_want_6_7</th>\n",
       "      <th>litpq_want_6_8</th>\n",
       "      <th>litpq_want_6_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>1. English/Welsh/Scottish/Northern Irish/British</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>7. White and Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>1. English/Welsh/Scottish/Northern Irish/British</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>1. English/Welsh/Scottish/Northern Irish/British</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>1. English/Welsh/Scottish/Northern Irish/British</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study        location ID Age  Gender     Sex   \\\n",
       "0      1  United Kingdom  1   21  Female  Female   \n",
       "1      1  United Kingdom  2   38  Female  Female   \n",
       "2      1  United Kingdom  4   23  Female  Female   \n",
       "3      1  United Kingdom  5   38  Female  Female   \n",
       "4      1  United Kingdom  6   20  Female  Female   \n",
       "\n",
       "                                          Ethnicity  Q41     Marital_status  \\\n",
       "0  1. English/Welsh/Scottish/Northern Irish/British  NaN  In a relationship   \n",
       "1                                7. White and Asian  NaN             Single   \n",
       "2  1. English/Welsh/Scottish/Northern Irish/British  NaN  In a relationship   \n",
       "3  1. English/Welsh/Scottish/Northern Irish/British  NaN            Married   \n",
       "4  1. English/Welsh/Scottish/Northern Irish/British  NaN             Single   \n",
       "\n",
       "                     religion  ... litpq_want_5_9 litpq_want_6_1  \\\n",
       "0           Strongly disagree  ...            0.0            2.0   \n",
       "1                    Disagree  ...            0.0            0.0   \n",
       "2           Strongly disagree  ...            0.0            7.0   \n",
       "3                    Disagree  ...           30.0           30.0   \n",
       "4  Neither agree nor disagree  ...            NaN            NaN   \n",
       "\n",
       "  litpq_want_6_2 litpq_want_6_3 litpq_want_6_4 litpq_want_6_5 litpq_want_6_6  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            3.0            1.0            1.0            1.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "  litpq_want_6_7 litpq_want_6_8 litpq_want_6_9  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            3.0            0.0  \n",
       "3            0.0            0.0           30.0  \n",
       "4            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'/Users/dhewitt/Data/Touch/SA/SA_qdata_unscored.csv', skiprows=[1,2]) #skipping empty lines from qualtrics\n",
    "#df = data.loc[:, ~data.columns.isin(['Progress','Duration (in seconds)','Finished','RecordedDate','Gender _6_TEXT','Sex _9_TEXT'])] #removes these cols - old version\n",
    "df = data.loc[:, ~data.columns.isin(['StartDate', 'EndDate', 'Status', 'IPAddress','Progress','Duration (in seconds)','Finished','RecordedDate','ResponseId','RecipientLastName','RecipientFirstName','RecipientEmail','ExternalReference','LocationLatitude','LocationLongitude','DistributionChannel','UserLanguage','Gender _6_TEXT','Sex _9_TEXT'])] #removes these cols\n",
    "df.to_csv('/Users/dhewitt/Data/Touch/SA/SA_qdata_unscored_original.csv', index=False)\n",
    "\n",
    "#Check if you want by uncommenting\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8e4ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicities, Religion and Gender have been recoded for analysis\n"
     ]
    }
   ],
   "source": [
    "recode_dict = {'1. English/Welsh/Scottish/Northern Irish/British' : 1, \n",
    "               '4. Any other White background, please describe on next page' : 4,\n",
    "               '6. White and Black African' : 6,\n",
    "              '7. White and Asian' : 7,\n",
    "               '8. Any other Mixed/Multiple ethnic background, please describe on next page' : 8,\n",
    "               '9. Indian' : 9,\n",
    "              '10. Pakistani' : 10,\n",
    "               '12. Chinese' : 12,\n",
    "               '13. Any other Asian background, please describe on next page' : 13,\n",
    "               '14. African' : 14,\n",
    "               '17. Arab' : 17,\n",
    "               '18. Ethnic group not listed here, please describe on next page' : 18}\n",
    "\n",
    "# Recode the values in column 'Loc_Cond'\n",
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i, 'Ethnicity'] in recode_dict:\n",
    "        df.loc[i, 'Ethnicity'] = recode_dict[df.loc[i, 'Ethnicity']]\n",
    "        \n",
    "recode_dict.clear()\n",
    "\n",
    "df = df.rename(columns={'Q41': 'EthnicityOther'})\n",
    "\n",
    "df=df.replace({'Female' : \"1\", 'United Kingdom' : \"UK\", 'Yes' : \"1\", 'No' : '0', 'No ' : '0'})\n",
    "\n",
    "# Recode the values in column 'Religion'\n",
    "recode_dict = {'Strongly Agree' : 2,\n",
    "              'Agree' : 1,\n",
    "              'Neither agree nor disagree' : 0,\n",
    "               'Disagree' : -1,\n",
    "               'Strongly disagree' : -2}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i, 'religion'] in recode_dict:\n",
    "        df.loc[i, 'religion'] = recode_dict[df.loc[i, 'religion']]\n",
    "recode_dict.clear()\n",
    "\n",
    "print(f'Ethnicities, Religion and Gender have been recoded for analysis')\n",
    "recode_dict.clear()\n",
    "\n",
    "#Check if you want by uncommenting\n",
    "#print(df.head())\n",
    "\n",
    "# Saving everything we have so far after some recoding\n",
    "#df.to_csv('/Users/dhewitt/Data/TouchStudy1/AllQuestionnaireData_recoded.csv', index=False)\n",
    "\n",
    "# Saving demographic data as a separate dataframe for easier analysis later\n",
    "demoDf = df.iloc[:,0:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355eac0",
   "metadata": {},
   "source": [
    "Time for summing questionnaire responses, starting with the ECR..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "012c9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the file ready for recoding questionnaire responses\n",
    "\n",
    "AnalysisDf = df.drop(df.columns[6:22], axis=1) #dropping the demographic data for simplicity - add back in at the end\n",
    "\n",
    "#Next, the recoding. Need to recode each one, iterating over rows of DataFrame, and make a new column which will have the result in\n",
    "\n",
    "ECR=AnalysisDf.iloc[:,6:42]\n",
    "ECR=ECR.replace({'Strongly Disagree\\n(1)' : \"1\", 'Disagree\\n(2)' : \"2\", 'Somewhat Disagree\\n(3)' : \"3\", 'Neither Agree Nor Disagree\\n(4)' : '4', 'Somewhat Agree\\n(5)' : '5', 'Agree\\n(6)' : '6', 'Strongly Agree\\n(7)' : '7', 'Somewhat Disagree (3)' : \"3\", 'Neither Agree Nor Disagree' : '4',})\n",
    "\n",
    "#ECR.columns.get_loc(\"ECR-R_18.1\")\n",
    "\n",
    "columnnames = [8,10,19,21,25,26,27,28,29,30,32,33,34,35]\n",
    "reversekeys = {'1' : '7', '2' : '6', '3' : '5', '5' : '3', '6' : '2', '7' : '1'}\n",
    "ECR.iloc[:,columnnames] = ECR.iloc[:,columnnames].replace(reversekeys)\n",
    "\n",
    "# Iterate over rows of the DataFrame\n",
    "for i in ECR.iterrows():\n",
    "    ECRAnx = i[1][0:18].astype(float).mean(skipna=True)\n",
    "    ECR.at[i[0], 'ECR_Anx'] = ECRAnx\n",
    "\n",
    "# Iterate over rows of the DataFrame\n",
    "for i in ECR.iterrows():\n",
    "    ECRAtt = i[1][18:36].astype(float).mean(skipna=True)\n",
    "    ECR.at[i[0], 'ECR_Att'] = ECRAtt\n",
    "\n",
    "# Iterate over rows of the DataFrame\n",
    "for i in ECR.iterrows():\n",
    "    ECRSum = i[1][0:36].astype(float).mean(skipna=True)\n",
    "    ECR.at[i[0], 'ECR_Sum'] = ECRSum\n",
    "\n",
    "#And now to add it all together to the AnalysisDf - which we currently aren't using but could be useful for exports without the demographic data\n",
    "AnalysisDf = pd.concat([AnalysisDf, ECR[['ECR_Anx', 'ECR_Att', 'ECR_Sum']]], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0093c07",
   "metadata": {},
   "source": [
    "Next to sum the TEAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "301c2dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Start by grabbing the data from the other df\n",
    "\n",
    "TEAQ=AnalysisDf.iloc[:,42:99]\n",
    "\n",
    "TEAQ = TEAQ.applymap(lambda x: x.strip() if isinstance(x, str) else x) #stripping trailing white space\n",
    "\n",
    "#Recoding the strings to numeric data\n",
    "TEAQ=TEAQ.replace({'Disagree strongly (1)' : \"1\", 'Disagree Strongly (1)' : '1', 'Disagree a little (2)' : \"2\", 'Neither agree nor disagree (3)' : '3', 'Neither Agree nor Disagree (3)' : '3', 'Agree a little (4)' : '4', 'Agree strongly (5)' : '5', 'Agree a little           (4)' :'4'})\n",
    "\n",
    "#reverse coding\n",
    "columnnames = [22,52,8,0,2,27,36,38] #index minus 1 because count starts from 0\n",
    "reversekeys = {'1' : '5', '2' : '4', '4' : '2', '5' : '1'}\n",
    "TEAQ.iloc[:,columnnames] = TEAQ.iloc[:,columnnames].replace(reversekeys)\n",
    "\n",
    "#Now running through each subscale to get a mean value for each one\n",
    "list=pd.Series([4, 13, 14, 16, 21, 30, 38, 48, 51, 56, 57]).sub(1)\n",
    "TEAQFFT = TEAQ.iloc[:,list]\n",
    "TEAQFFT = pd.Series(TEAQFFT.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "list=pd.Series([11, 17, 18, 23, 25, 27, 29, 36, 41, 45, 46, 49, 53, 54]).sub(1)\n",
    "TEAQCIT = TEAQ.iloc[:,list]\n",
    "TEAQCIT = pd.Series(TEAQCIT.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "list=pd.Series([5, 6, 9, 15, 22, 32, 33, 35, 42]).sub(1)\n",
    "TEAQCHT = TEAQ.iloc[:,list]\n",
    "TEAQCHT = pd.Series(TEAQCHT.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "list=pd.Series([2, 7, 43, 52, 55]).sub(1)\n",
    "TEAQASC = TEAQ.iloc[:,list]\n",
    "TEAQASC = pd.Series(TEAQASC.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "list=pd.Series([8, 10, 12, 19, 20, 24, 26, 31, 34, 40, 44, 47, 50]).sub(1)\n",
    "TEAQAIT = TEAQ.iloc[:,list]\n",
    "TEAQAIT = pd.Series(TEAQAIT.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "list=pd.Series([1, 3, 28, 37, 39]).sub(1)\n",
    "TEAQAUT = TEAQ.iloc[:,list]\n",
    "TEAQAUT = pd.Series(TEAQAUT.astype(float).mean(axis=1, skipna=True))\n",
    "\n",
    "#TEAQSUM = pd.Series(TEAQ.astype(int).mean(axis=1)) #removed\n",
    "\n",
    "#Adding to a new dataframe - old, with TEAQSUM\n",
    "#ALLTEAQ = pd.concat([TEAQFFT, TEAQCIT, TEAQCHT, TEAQASC, TEAQAIT, TEAQAUT, TEAQSUM], axis=1, ignore_index=True)\n",
    "#ALLTEAQ.columns = [\"TEAQ_FFT\", \"TEAQ_CIT\", \"TEAQ_CHT\", \"TEAQ_ASC\", \"TEAQ_AIT\", \"TEAQ_AUT\", \"TEAQ_SUM\"]\n",
    "\n",
    "ALLTEAQ = pd.concat([TEAQFFT, TEAQCIT, TEAQCHT, TEAQASC, TEAQAIT, TEAQAUT], axis=1, ignore_index=True)\n",
    "ALLTEAQ.columns = [\"TEAQ_FFT\", \"TEAQ_CIT\", \"TEAQ_CHT\", \"TEAQ_ASC\", \"TEAQ_AIT\", \"TEAQ_AUT\"]\n",
    "\n",
    "#Join to AnalysisDf incase you want to save that later\n",
    "AnalysisDf = AnalysisDf.join(ALLTEAQ)\n",
    "\n",
    "#TEAQ.to_csv('/Users/dhewitt/Data/TouchStudy1/TEAQ_recoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a31b496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/8l65rzcd5x5903xt73lz9ln00000gn/T/ipykernel_62269/1715886617.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  did = pd.Series(LITPQ.loc[:, LITPQ.columns.str.contains('litpq_did')].sum(axis=1))\n"
     ]
    }
   ],
   "source": [
    "#temporary fix = average over all did and want for ratio, rather than by agent\n",
    "#AnalysisDf.columns.get_loc(\"litpq_want_6_9\")\n",
    "LITPQ=AnalysisDf.iloc[:,99:207]\n",
    "\n",
    "did = pd.Series(LITPQ.loc[:, LITPQ.columns.str.contains('litpq_did')].sum(axis=1))\n",
    "want = pd.Series(LITPQ.loc[:, LITPQ.columns.str.contains('litpq_want')].sum(axis=1))\n",
    "ratio = pd.Series((want/did), name = 'LITPQ_RATIO') #note: divide by zero error results in error when did is 0 - comes up as 'inf'\n",
    "AnalysisDf = pd.concat([AnalysisDf, ratio], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f1bd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS WILL BE FOR WORKING OUT LITPQ OVER EACH TOUCH AGENT\n",
    "#AnalysisDf.columns.get_loc(\"litpq_want_6_9\") #resolve NaNs\n",
    "#LITPQ=AnalysisDf.iloc[:,99:207]\n",
    "\n",
    "#ratio = pd.DataFrame()\n",
    "#for i in range(1, 10):\n",
    " #   did = pd.Series(LITPQ.loc[:, LITPQ.columns.str.contains('litpq_did_\\d_{i}')].sum(axis=1))\n",
    "  #  want = pd.Series(LITPQ.loc[:, LITPQ.columns.str.contains('litpq_want_\\d_{i}')].sum(axis=1))\n",
    "   # ratio[f'ratio_{i}'] = want/did #divide by zero error results in error when did is 0 - add a constant?\n",
    "\n",
    "#LITPQ = pd.concat([LITPQ, ratio], axis=1) #results in NaNs for all data ?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b4d898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to save AnalysisDf to own csv file - optionally by adding the demographic data back in\n",
    "\n",
    "#AnalysisDf = pd.concat([AnalysisDf, df.iloc[:,6:22]], axis=1) #Demographic data\n",
    "#AnalysisDf.to_csv('/Users/dhewitt/Data/TouchStudy1/AnalysisQuestionnaireData_recoded.csv', index=False) #Saving all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "418e800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>location</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EthnicityOther</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>litpq_want_6_1</th>\n",
       "      <th>litpq_want_6_2</th>\n",
       "      <th>litpq_want_6_3</th>\n",
       "      <th>litpq_want_6_4</th>\n",
       "      <th>litpq_want_6_5</th>\n",
       "      <th>litpq_want_6_6</th>\n",
       "      <th>litpq_want_6_7</th>\n",
       "      <th>litpq_want_6_8</th>\n",
       "      <th>litpq_want_6_9</th>\n",
       "      <th>LITPQ_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study location ID Age  Gender  Sex   Ethnicity EthnicityOther  \\\n",
       "0      1       UK  1   21       1    1        1.0            NaN   \n",
       "1      1       UK  2   38       1    1        7.0            NaN   \n",
       "2      1       UK  4   23       1    1        1.0            NaN   \n",
       "3      1       UK  5   38       1    1        1.0            NaN   \n",
       "4      1       UK  6   20       1    1        1.0            NaN   \n",
       "\n",
       "      Marital_status religion  ... litpq_want_6_1 litpq_want_6_2  \\\n",
       "0  In a relationship       -2  ...            2.0            0.0   \n",
       "1             Single       -1  ...            0.0            0.0   \n",
       "2  In a relationship       -2  ...            7.0            3.0   \n",
       "3            Married       -1  ...           30.0            0.0   \n",
       "4             Single        0  ...            NaN            NaN   \n",
       "\n",
       "  litpq_want_6_3 litpq_want_6_4 litpq_want_6_5 litpq_want_6_6 litpq_want_6_7  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            1.0            1.0            1.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "  litpq_want_6_8 litpq_want_6_9 LITPQ_RATIO  \n",
       "0            0.0            0.0    1.000000  \n",
       "1            0.0            0.0    0.818182  \n",
       "2            3.0            0.0    2.795918  \n",
       "3            0.0           30.0    1.000000  \n",
       "4            NaN            NaN    1.571429  \n",
       "\n",
       "[5 rows x 233 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final exports\n",
    "\n",
    "FinalDf = pd.concat([demoDf, ECR, TEAQ, ALLTEAQ, LITPQ, ratio],axis=1)\n",
    "FinalDf.to_csv('/Users/dhewitt/Data/Touch/SA/AllQuestionnaireData_SA_UK_recoded.csv', index=False)\n",
    "\n",
    "#Uncomment to view\n",
    "FinalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97467d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  location  STUDY  ID  Age  Gender  Sex  Ethnicity EthnicityOther  \\\n",
      "0       UK      2   1    51       1    1         §            NaN   \n",
      "1       UK      2   1    51       1    1         §            NaN   \n",
      "2       UK      2   1    51       1    1         §            NaN   \n",
      "3       UK      2   1    51       1    1         §            NaN   \n",
      "4       UK      2   2    25       1    1         1            NaN   \n",
      "\n",
      "  Marital_status religion  ... litpq_want_6_3 litpq_want_6_4 litpq_want_6_5  \\\n",
      "0        Married        1  ...            0.0            0.0            0.0   \n",
      "1        Married        1  ...            0.0            0.0            0.0   \n",
      "2        Married        1  ...            0.0            0.0            0.0   \n",
      "3        Married        1  ...            0.0            0.0            0.0   \n",
      "4         Single       -1  ...            0.0            2.0            3.0   \n",
      "\n",
      "  litpq_want_6_6 litpq_want_6_7 litpq_want_6_8 litpq_want_6_9 LITPQ_RATIO  \\\n",
      "0            0.0            0.0            0.0            0.0    0.960784   \n",
      "1            0.0            0.0            0.0            0.0    0.960784   \n",
      "2            0.0            0.0            0.0            0.0    0.960784   \n",
      "3            0.0            0.0            0.0            0.0    0.960784   \n",
      "4            0.0            0.0            0.0            0.0    0.923077   \n",
      "\n",
      "  SELF_TOUCH_INSTANCE SELF_TOUCH_DUR  \n",
      "0                 1.0          112.0  \n",
      "1                 1.0          112.0  \n",
      "2                 1.0          112.0  \n",
      "3                 1.0          112.0  \n",
      "4                15.0          238.0  \n",
      "\n",
      "[5 rows x 236 columns]\n"
     ]
    }
   ],
   "source": [
    "#Adding Self Touch Measures Coded from Videos - for CE-UK Collaboration only\n",
    "data = pd.read_csv('/Users/dhewitt/Data/Touch/selftouch.csv')\n",
    "newdata = pd.merge(FinalDf,data,on=[\"ID\",\"STUDY\"])\n",
    "study1 = FinalDf.loc[FinalDf['STUDY'] == 1]\n",
    "newdata = pd.concat([newdata,study1])\n",
    "#print(newdata.head())\n",
    "newdata.to_csv('/Users/dhewitt/Data/Touch/SA/AllQuestionnaireData_withSelfTouch_recoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98525f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cef0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
